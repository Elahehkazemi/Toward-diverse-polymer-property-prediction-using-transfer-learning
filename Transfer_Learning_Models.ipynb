{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50a5683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import math as math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import loadtxt\n",
    "from numpy.random import seed\n",
    "import random\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression, make_blobs\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing, metrics, model_selection\n",
    "\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "\n",
    "import optuna\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a571d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "\n",
    "xls1 = pd.ExcelFile('polymer properties')\n",
    "\n",
    "file_part1  = pd.DataFrame()\n",
    "\n",
    "num =0 \n",
    "while num < 109:\n",
    "    part1 = pd.read_excel(xls1,'descriptors.xls_'+ str(num))\n",
    "    file_part1 = pd.concat([file_part1,part1], axis=1)\n",
    "    num +=1\n",
    "\n",
    "count =0\n",
    "\n",
    "\n",
    "dataset = file_part1.values\n",
    "\n",
    "print(dataset.shape)\n",
    "\n",
    "\n",
    "#name\n",
    "A  = dataset [:, 1]\n",
    "#X is the value of descriptors\n",
    "X = dataset [:,3:]\n",
    "Y = dataset [:,2]\n",
    "print(X.shape)\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "# Instantiate a PCA object with 6 components\n",
    "pca = PCA(n_components=13)\n",
    "\n",
    "# Fit the PCA model to your scaled dataset\n",
    "X_pca = pca.fit_transform(X_scale)\n",
    "\n",
    "\n",
    "X_cp= X_pca[:123]\n",
    "Y_cp=Y[:123]\n",
    "\n",
    "X_cv= X_pca[123:133]\n",
    "Y_cv=Y[123:133]\n",
    "\n",
    "X_flexural= X_pca[133:146]\n",
    "Y_flexural=Y[133:146]\n",
    "\n",
    "\n",
    "\n",
    "X_shear= X_pca[146:164]\n",
    "Y_shear=Y[146:164]\n",
    "\n",
    "\n",
    "X_dynamic= X_pca[164:]\n",
    "Y_dynamic=Y[164:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a631d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict flexural stress\n",
    "#load svaed model\n",
    "\n",
    "base_model= load_model('Model.h5')\n",
    "base_model.layers.pop()\n",
    "base_model.trainable = True\n",
    "\n",
    "\n",
    "tf.keras.utils.set_random_seed(77)\n",
    "\n",
    "# Define the model creation function with Optuna\n",
    "def create_model(trial):\n",
    "    # Start with the base model\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Add existing layers from the base model\n",
    "    for layer in base_model.layers:\n",
    "        model.add(layer)\n",
    "\n",
    "    # Define the number of additional layers to add\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 5)  # Choose between 1 and 5 additional layers\n",
    "\n",
    "    # Add additional layers as specified by Optuna\n",
    "    for i in range(n_layers):\n",
    "        n_units = trial.suggest_int(f'units_{i}', 10, 128)  # Choose between 10 and 128 units\n",
    "        activation = trial.suggest_categorical(f'activation_{i}', ['relu', 'sigmoid', 'tanh', 'linear'])\n",
    "        model.add(keras.layers.Dense(n_units, activation=activation))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(keras.layers.Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss='mse', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    model.fit(X_flexural_train, Y_flexural_train, epochs=380, batch_size=2, verbose=0)\n",
    "    # Evaluate the model on the test set\n",
    "    score = model.evaluate(X_flexural_test, Y_flexural_test, verbose=0)\n",
    "    return score[0]  # Return the loss\n",
    "\n",
    "# Create a study object and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)  # Adjust the number of trials as needed\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "\n",
    "# Optionally, retrain the model with the best hyperparameters\n",
    "best_model = create_model(study.best_trial)\n",
    "best_model.fit(X_flexural_train, Y_flexural_train, epochs=380, batch_size=2, verbose=1)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "test_loss = best_model.evaluate(X_flexural_test, Y_flexural_test)\n",
    "print(\"Test loss of the best model: \", test_loss)\n",
    "\n",
    "\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "Y_flexural_pred_train = NEW_MODEL.predict(X_flexural_train)\n",
    "Y_flexural_pred_test = NEW_MODEL.predict(X_flexural_test)\n",
    "R2train = r2_score(Y_flexural_train, Y_flexural_pred_train)\n",
    "train_results.append(R2train)\n",
    "R2test = r2_score(Y_flexural_test, Y_flexural_pred_test)\n",
    "test_results.append(R2test)\n",
    "from sklearn import metrics\n",
    "print('Mean Absolute Error of train:', metrics.mean_absolute_error(Y_flexural_train,Y_flexural_pred_train))\n",
    "print('Mean Absolute Error of test:', metrics.mean_absolute_error(Y_flexural_test,Y_flexural_pred_test))\n",
    "print('Max random state for train set:', max((train_results)))\n",
    "print('Max random state for test set:', max((test_results)))\n",
    "\n",
    "mse_train = mean_squared_error(Y_flexural_train, Y_flexural_pred_train)\n",
    "mse_test = mean_squared_error(Y_flexural_test, Y_flexural_pred_test)\n",
    "\n",
    "mse_per_sample_train = mse_train / len(Y_flexural_train)\n",
    "mse_per_sample_test = mse_test / len(Y_flexural_test)\n",
    "\n",
    "print('MSE per sample on train set:', mse_per_sample_train)\n",
    "print('MSE per sample on test set:', mse_per_sample_test)\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(dpi=200)\n",
    "\n",
    "x =[0,0.25]\n",
    "y =[0,0.25]\n",
    "plt.plot(x, y, '--', color = 'k')\n",
    "plt.xlim(0,0.25)\n",
    "plt.ylim(0,0.25)\n",
    "\n",
    "\n",
    "plt.plot(Y_flexural_train, Y_flexural_pred_train, 'o', color = '#FFFF00', label = \"Training set\")\n",
    "plt.plot(Y_flexural_test, Y_flexural_pred_test, 'o', color = 'k', label = \"Test set\")\n",
    "plt.xlabel('Expected Flexural stress (GPa)',labelpad=12,fontsize= 12,fontname ='Times New Roman') \n",
    "plt.ylabel('Predicted Flexural stress (GPa)',labelpad=12,fontsize= 12,fontname ='Times New Roman')\n",
    "\n",
    "ax = plt.gca()\n",
    "for axis in ['top','bottom','left','right']:\n",
    "  ax.spines[axis].set_linewidth(1.5)\n",
    "\n",
    "plt.tick_params(axis='x', direction='in')\n",
    "plt.tick_params(axis='y', direction='in')\n",
    "\n",
    "plt.legend(loc='best',fontsize=10) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba1cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict Cv:\n",
    "#load svaed model\n",
    "base_model= load_model('Model.h5')\n",
    "base_model.layers.pop()\n",
    "base_model.trainable = True\n",
    "\n",
    "\n",
    "X_cv_train, X_cv_test, Y_cv_train, Y_cv_test = train_test_split (X_cv, Y_cv, test_size=0.3,random_state =64)\n",
    "\n",
    "X_cv_test=np.array(X_cv_test).astype(\"float\")\n",
    "Y_cv_test=np.array(Y_cv_test).astype(\"float\")\n",
    "X_cv_train=np.array(X_cv_train).astype(\"float\")\n",
    "Y_cv_train=np.array(Y_cv_train).astype(\"float\")\n",
    "\n",
    "tf.keras.utils.set_random_seed(36)\n",
    "\n",
    "# Define the model creation function with Optuna\n",
    "def create_model(trial):\n",
    "    # Start with the base model\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Add existing layers from the base model\n",
    "    for layer in base_model.layers[:-1]:  # Exclude the last layer\n",
    "        model.add(layer)\n",
    "\n",
    "    # Define the number of additional layers to add\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 5)  # Choose between 1 and 5 additional layers\n",
    "\n",
    "    # Add additional layers as specified by Optuna\n",
    "    for i in range(n_layers):\n",
    "        n_units = trial.suggest_int(f'units_{i}', 10, 128)  # Choose between 10 and 128 units\n",
    "        activation = trial.suggest_categorical(f'activation_{i}', ['relu', 'sigmoid', 'tanh', 'linear'])\n",
    "        model.add(keras.layers.Dense(n_units, activation=activation))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(keras.layers.Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile the model with a learning rate suggested by Optuna\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss='mse', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    model.fit(X_cv_train, Y_cv_train, epochs=500, batch_size=3, verbose=0)\n",
    "    # Evaluate the model on the test set\n",
    "    score = model.evaluate(X_cv_test, Y_cv_test, verbose=0)\n",
    "    return score[0]  # Return the loss\n",
    "\n",
    "# Create a study object and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)  # Adjust the number of trials as needed\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "\n",
    "# Optionally, retrain the model with the best hyperparameters\n",
    "best_model = create_model(study.best_trial)\n",
    "best_model.fit(X_cv_train, Y_cv_train, epochs=500, batch_size=3, verbose=1)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "test_loss = best_model.evaluate(X_cv_test, Y_cv_test)\n",
    "print(\"Test loss of the best model: \", test_loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "Y_cv_pred_train = NEW_MODEL.predict(X_cv_train)\n",
    "Y_cv_pred_test = NEW_MODEL.predict(X_cv_test)\n",
    "R2train = r2_score(Y_cv_train, Y_cv_pred_train)\n",
    "train_results.append(R2train)\n",
    "R2test = r2_score(Y_cv_test, Y_cv_pred_test)\n",
    "test_results.append(R2test)\n",
    "from sklearn import metrics\n",
    "print('Mean Absolute Error of train:', metrics.mean_absolute_error(Y_cv_train,Y_cv_pred_train))\n",
    "print('Mean Absolute Error of test:', metrics.mean_absolute_error(Y_cv_test,Y_cv_pred_test))\n",
    "print('Max random state for train set:', max((train_results)))\n",
    "print('Max random state for test set:', max((test_results)))\n",
    "\n",
    "mse_train = mean_squared_error(Y_cv_train, Y_cv_pred_train)\n",
    "mse_test = mean_squared_error(Y_cv_test, Y_cv_pred_test)\n",
    "\n",
    "mse_per_sample_train = mse_train / len(Y_cv_train)\n",
    "mse_per_sample_test = mse_test / len(Y_cv_test)\n",
    "\n",
    "print('MSE per sample on train set:', mse_per_sample_train)\n",
    "print('MSE per sample on test set:', mse_per_sample_test)\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(dpi=200)\n",
    "\n",
    "x =[0.2,0.5]\n",
    "y =[0.2,0.5]\n",
    "plt.plot(x, y, '--', color = 'k')\n",
    "plt.xlim(0.2,0.5)\n",
    "plt.ylim(0.2,0.5)\n",
    "\n",
    "\n",
    "plt.plot(Y_cv_train, Y_cv_pred_train, 'o', color = '#FF69B4', label = \"Training set\")\n",
    "plt.plot(Y_cv_test, Y_cv_pred_test, 'o', color = 'k', label = \"Test set\")\n",
    "plt.xlabel('Expected $C_{v}$ (cal/g.C)',labelpad=12,fontsize= 12,fontname ='Times New Roman') \n",
    "plt.ylabel('Predicted $C_{v}$ (cal/g.C)',labelpad=12,fontsize= 12,fontname ='Times New Roman')\n",
    "\n",
    "ax = plt.gca()\n",
    "for axis in ['top','bottom','left','right']:\n",
    "  ax.spines[axis].set_linewidth(1.5)\n",
    "\n",
    "plt.tick_params(axis='x', direction='in')\n",
    "plt.tick_params(axis='y', direction='in')\n",
    "\n",
    "plt.legend(loc='best',fontsize=10) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8c300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict shear strength :\n",
    "#load svaed model\n",
    "\n",
    "base_model= load_model('Base model.h5')\n",
    "base_model.layers.pop()\n",
    "base_model.trainable = True\n",
    "\n",
    "\n",
    "X_shear_train, X_shear_test, Y_shear_train, Y_shear_test = train_test_split (X_shear, Y_shear, test_size=0.3,random_state =24)#24\n",
    "\n",
    "X_shear_test=np.array(X_shear_test).astype(\"float\")\n",
    "Y_shear_test=np.array(Y_shear_test).astype(\"float\")\n",
    "X_shear_train=np.array(X_shear_train).astype(\"float\")\n",
    "Y_shear_train=np.array(Y_shear_train).astype(\"float\")\n",
    "\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.keras.utils.set_random_seed(39)\n",
    "\n",
    "# Define the model creation function with Optuna\n",
    "def create_model(trial):\n",
    "    # Start with the base model\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Add existing layers from the base model\n",
    "    for layer in base_model.layers[:-1]:  # Exclude the last layer\n",
    "        model.add(layer)\n",
    "\n",
    "    # Define the number of additional layers to add\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 5)  # Choose between 1 and 5 additional layers\n",
    "\n",
    "    # Add additional layers as specified by Optuna\n",
    "    for i in range(n_layers):\n",
    "        n_units = trial.suggest_int(f'units_{i}', 10, 128)  # Choose between 10 and 128 units\n",
    "        activation = trial.suggest_categorical(f'activation_{i}', ['relu', 'sigmoid', 'tanh', 'linear'])\n",
    "        model.add(keras.layers.Dense(n_units, activation=activation))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(keras.layers.Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile the model with a learning rate suggested by Optuna\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss='mse', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    model.fit(X_shear_train, Y_shear_train, epochs=275, batch_size=3, verbose=0)\n",
    "    # Evaluate the model on the test set\n",
    "    score = model.evaluate(X_shear_test, Y_shear_test, verbose=0)\n",
    "    return score[0]  # Return the loss\n",
    "\n",
    "# Create a study object and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)  # Adjust the number of trials as needed\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "\n",
    "# Optionally, retrain the model with the best hyperparameters\n",
    "best_model = create_model(study.best_trial)\n",
    "best_model.fit(X_shear_train, Y_shear_train, epochs=275, batch_size=3, verbose=1)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "test_loss = best_model.evaluate(X_shear_test, Y_shear_test)\n",
    "print(\"Test loss of the best model: \", test_loss)\n",
    "\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "Y_shear_pred_train = NEW_MODEL.predict(X_shear_train)\n",
    "Y_shear_pred_test = NEW_MODEL.predict(X_shear_test)\n",
    "R2train = r2_score(Y_shear_train, Y_shear_pred_train)\n",
    "train_results.append(R2train)\n",
    "R2test = r2_score(Y_shear_test, Y_shear_pred_test)\n",
    "test_results.append(R2test)\n",
    "from sklearn import metrics\n",
    "print('Mean Absolute Error of train:', metrics.mean_absolute_error(Y_shear_train,Y_shear_pred_train))\n",
    "print('Mean Absolute Error of test:', metrics.mean_absolute_error(Y_shear_test,Y_shear_pred_test))\n",
    "print('Max random state for train set:', max((train_results)))\n",
    "print('Max random state for test set:', max((test_results)))\n",
    "\n",
    "\n",
    "mse_train = mean_squared_error(Y_shear_train, Y_shear_pred_train)\n",
    "mse_test = mean_squared_error(Y_shear_test, Y_shear_pred_test)\n",
    "\n",
    "mse_per_sample_train = mse_train / len(Y_shear_train)\n",
    "mse_per_sample_test = mse_test / len(Y_shear_test)\n",
    "\n",
    "print('MSE per sample on train set:', mse_per_sample_train)\n",
    "print('MSE per sample on test set:', mse_per_sample_test)\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(dpi=200)\n",
    "\n",
    "x =[0,1.5]\n",
    "y =[0,1.5]\n",
    "plt.plot(x, y, '--', color = 'k')\n",
    "plt.xlim(0,1.5)\n",
    "plt.ylim(0,1.5)\n",
    "\n",
    "\n",
    "plt.plot(Y_shear_train, Y_shear_pred_train, 'o', color = '#BFEFFF', label = \"Training set\")\n",
    "plt.plot(Y_shear_test, Y_shear_pred_test, 'o', color = 'k', label = \"Test set\")\n",
    "plt.xlabel('Expected Shear Modulus (GPa)',labelpad=12,fontsize= 12,fontname ='Times New Roman') \n",
    "plt.ylabel('Predicted Shear Modulus(GPa)',labelpad=12,fontsize= 12,fontname ='Times New Roman')\n",
    "\n",
    "ax = plt.gca()\n",
    "for axis in ['top','bottom','left','right']:\n",
    "  ax.spines[axis].set_linewidth(1.5)\n",
    "\n",
    "plt.tick_params(axis='x', direction='in')\n",
    "plt.tick_params(axis='y', direction='in')\n",
    "\n",
    "plt.legend(loc='best',fontsize=10) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed903d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict dynamic viscosity:\n",
    "#load svaed model\n",
    "\n",
    "base_model= load_model('Base model.h5')\n",
    "base_model.layers.pop()\n",
    "base_model.trainable = True\n",
    "\n",
    "\n",
    "X_dynamic_train, X_dynamic_test, Y_dynamic_train, Y_dynamic_test = train_test_split (X_dynamic, Y_dynamic,test_size=0.3,\n",
    "                                        random_state =190)\n",
    "\n",
    "X_dynamic_test=np.array(X_dynamic_test).astype(\"float\")\n",
    "Y_dynamic_test=np.array(Y_dynamic_test).astype(\"float\")\n",
    "X_dynamic_train=np.array(X_dynamic_train).astype(\"float\")\n",
    "Y_dynamic_train=np.array(Y_dynamic_train).astype(\"float\")\n",
    "\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.keras.utils.set_random_seed(70)\n",
    "\n",
    "# Define the model creation function with Optuna\n",
    "def create_model(trial):\n",
    "    # Start with the base model\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Add existing layers from the base model\n",
    "    for layer in base_model.layers[:-1]:  # Exclude the last layer\n",
    "        model.add(layer)\n",
    "\n",
    "    # Define the number of additional layers to add\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 5)  # Choose between 1 and 5 additional layers\n",
    "\n",
    "    # Add additional layers as specified by Optuna\n",
    "    for i in range(n_layers):\n",
    "        n_units = trial.suggest_int(f'units_{i}', 10, 512)  # Choose between 10 and 512 units\n",
    "        activation = trial.suggest_categorical(f'activation_{i}', ['sigmoid', 'relu', 'tanh', 'linear'])\n",
    "        model.add(keras.layers.Dense(n_units, activation=activation))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(keras.layers.Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile the model with a learning rate suggested by Optuna\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss='mse', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    model.fit(X_dynamic_train, Y_dynamic_train, epochs=850, batch_size=3, verbose=0)\n",
    "    # Evaluate the model on the test set\n",
    "    score = model.evaluate(X_dynamic_test, Y_dynamic_test, verbose=0)\n",
    "    return score[0]  # Return the loss\n",
    "\n",
    "# Create a study object and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)  # Adjust the number of trials as needed\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "\n",
    "# Optionally, retrain the model with the best hyperparameters\n",
    "best_model = create_model(study.best_trial)\n",
    "best_model.fit(X_dynamic_train, Y_dynamic_train, epochs=850, batch_size=3, verbose=1)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "test_loss = best_model.evaluate(X_dynamic_test, Y_dynamic_test)\n",
    "print(\"Test loss of the best model: \", test_loss)\n",
    "\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "Y_dynamic_pred_train = NEW_MODEL.predict(X_dynamic_train)\n",
    "Y_dynamic_pred_test = NEW_MODEL.predict(X_dynamic_test)\n",
    "R2train = r2_score(Y_dynamic_train, Y_dynamic_pred_train)\n",
    "train_results.append(R2train)\n",
    "R2test = r2_score(Y_dynamic_test, Y_dynamic_pred_test)\n",
    "test_results.append(R2test)\n",
    "from sklearn import metrics\n",
    "print('Mean Absolute Error of train:', metrics.mean_absolute_error(Y_dynamic_train,Y_dynamic_pred_train))\n",
    "print('Mean Absolute Error of test:', metrics.mean_absolute_error(Y_dynamic_test,Y_dynamic_pred_test))\n",
    "print('Max random state for train set:', max((train_results)))\n",
    "print('Max random state for test set:', max((test_results)))\n",
    "\n",
    "\n",
    "mse_train = mean_squared_error(Y_dynamic_train, Y_dynamic_pred_train)\n",
    "mse_test = mean_squared_error(Y_dynamic_test, Y_dynamic_pred_test)\n",
    "\n",
    "mse_per_sample_train = mse_train / len(Y_dynamic_train)\n",
    "mse_per_sample_test = mse_test / len(Y_dynamic_test)\n",
    "\n",
    "print('MSE per sample on train set:', mse_per_sample_train)\n",
    "print('MSE per sample on test set:', mse_per_sample_test)\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(dpi=200)\n",
    "\n",
    "x =[0,3]\n",
    "y =[0,3]\n",
    "plt.plot(x, y, '--', color = 'k')\n",
    "plt.xlim(0,3)\n",
    "plt.ylim(0,3)\n",
    "\n",
    "\n",
    "plt.plot(Y_dynamic_train, Y_dynamic_pred_train, 'o', color = '#4B0082', label = \"Training set\")\n",
    "plt.plot(Y_dynamic_test, Y_dynamic_pred_test, 'o', color = 'k', label = \"Test set\")\n",
    "plt.xlabel('Expected Dynamic Viscosity (Pa.s)',labelpad=12,fontsize= 12,fontname ='Times New Roman') \n",
    "plt.ylabel('Predicted Dynamic Viscosity (Pa.s)',labelpad=12,fontsize= 12,fontname ='Times New Roman')\n",
    "\n",
    "ax = plt.gca()\n",
    "for axis in ['top','bottom','left','right']:\n",
    "  ax.spines[axis].set_linewidth(1.5)\n",
    "\n",
    "plt.tick_params(axis='x', direction='in')\n",
    "plt.tick_params(axis='y', direction='in')\n",
    "\n",
    "plt.legend(loc='best',fontsize=10) \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
